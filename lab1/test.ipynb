{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from tn import layers, activation, loss\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "fc1 = layers.FCLayer(10, 16)\n",
    "fc2 = layers.FCLayer(16, 32)\n",
    "relu = activation.ReLU()\n",
    "sm = activation.Softmax()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.03122686, 0.03127055, 0.03125132, 0.03124358, 0.03124098,\n        0.03128767, 0.03124057, 0.03131574, 0.03121658, 0.03121635,\n        0.03124852, 0.03124931, 0.03123817, 0.03123491, 0.03126666,\n        0.03125142, 0.03128915, 0.03120097, 0.03123925, 0.03123496,\n        0.03128156, 0.03129376, 0.03125161, 0.03122403, 0.03119997,\n        0.03126399, 0.03122912, 0.03124464, 0.03127547, 0.03121821,\n        0.03126621, 0.03128792]])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = fc1.forward(np.random.random((1, 10)))\n",
    "out = relu.forward(out)\n",
    "out = fc2.forward(out)\n",
    "out = sm.forward(out)\n",
    "out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "3.46363433088358"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crit = loss.CrossEntropyLoss()\n",
    "crit.calculate(out, [7])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "cl = layers.Conv2D(3, 16)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[[[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]],\n\n        [[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]],\n\n        [[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]],\n\n        ...,\n\n        [[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]],\n\n        [[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]],\n\n        [[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]],\n\n\n       [[[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]],\n\n        [[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]],\n\n        [[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]],\n\n        ...,\n\n        [[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]],\n\n        [[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]],\n\n        [[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]],\n\n\n       [[[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]],\n\n        [[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]],\n\n        [[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]],\n\n        ...,\n\n        [[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]],\n\n        [[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]],\n\n        [[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]],\n\n\n       ...,\n\n\n       [[[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]],\n\n        [[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]],\n\n        [[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]],\n\n        ...,\n\n        [[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]],\n\n        [[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]],\n\n        [[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]],\n\n\n       [[[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]],\n\n        [[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]],\n\n        [[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]],\n\n        ...,\n\n        [[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]],\n\n        [[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]],\n\n        [[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]],\n\n\n       [[[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]],\n\n        [[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]],\n\n        [[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]],\n\n        ...,\n\n        [[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]],\n\n        [[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]],\n\n        [[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]]])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.forward(np.random.random((8, 3, 256, 256)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "model = layers.Sequential(\n",
    "    layers.FCLayer(n_input=2, n_output=10),\n",
    "    activation.ReLU(),\n",
    "    layers.FCLayer(n_input=10, n_output=1),\n",
    "    activation.Sigmoid()\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1 | Loss: 0.750221459694764\n",
      "Epoch:2 | Loss: 0.7502150687673531\n",
      "Epoch:3 | Loss: 0.7502086778984799\n",
      "Epoch:4 | Loss: 0.750202287087654\n",
      "Epoch:5 | Loss: 0.7501958963342272\n",
      "Epoch:6 | Loss: 0.7501895056377923\n",
      "Epoch:7 | Loss: 0.7501831149979257\n",
      "Epoch:8 | Loss: 0.7501767244141387\n",
      "Epoch:9 | Loss: 0.7501703338859393\n",
      "Epoch:10 | Loss: 0.7501639434122701\n",
      "Epoch:11 | Loss: 0.7501575529907222\n",
      "Epoch:12 | Loss: 0.7501511626232822\n",
      "Epoch:13 | Loss: 0.7501447723094546\n",
      "Epoch:14 | Loss: 0.750138382048746\n",
      "Epoch:15 | Loss: 0.7501319918406664\n",
      "Epoch:16 | Loss: 0.7501256016847185\n",
      "Epoch:17 | Loss: 0.7501192115804078\n",
      "Epoch:18 | Loss: 0.7501128215272389\n",
      "Epoch:19 | Loss: 0.7501064315247182\n",
      "Epoch:20 | Loss: 0.7501000415728513\n",
      "Epoch:21 | Loss: 0.7500936516706441\n",
      "Epoch:22 | Loss: 0.7500872618175954\n",
      "Epoch:23 | Loss: 0.7500808720130409\n",
      "Epoch:24 | Loss: 0.7500744822565811\n",
      "Epoch:25 | Loss: 0.7500680925477928\n",
      "Epoch:26 | Loss: 0.7500617028861757\n",
      "Epoch:27 | Loss: 0.7500553132712373\n",
      "Epoch:28 | Loss: 0.7500489237024757\n",
      "Epoch:29 | Loss: 0.7500425341793969\n",
      "Epoch:30 | Loss: 0.7500361447014973\n",
      "Epoch:31 | Loss: 0.7500297552682681\n",
      "Epoch:32 | Loss: 0.7500233658792188\n",
      "Epoch:33 | Loss: 0.7500169765338542\n",
      "Epoch:34 | Loss: 0.7500105872316797\n",
      "Epoch:35 | Loss: 0.7500041979720596\n",
      "Epoch:36 | Loss: 0.749997808752359\n",
      "Epoch:37 | Loss: 0.7499914195750212\n",
      "Epoch:38 | Loss: 0.7499850304390833\n",
      "Epoch:39 | Loss: 0.7499786413439136\n",
      "Epoch:40 | Loss: 0.7499722522889237\n",
      "Epoch:41 | Loss: 0.7499658632736164\n",
      "Epoch:42 | Loss: 0.7499594742972581\n",
      "Epoch:43 | Loss: 0.7499530853595534\n",
      "Epoch:44 | Loss: 0.7499466964600229\n",
      "Epoch:45 | Loss: 0.7499403075981604\n",
      "Epoch:46 | Loss: 0.7499339187734627\n",
      "Epoch:47 | Loss: 0.7499275299854303\n",
      "Epoch:48 | Loss: 0.7499211412335581\n",
      "Epoch:49 | Loss: 0.7499147525173396\n",
      "Epoch:50 | Loss: 0.7499083638362728\n",
      "Epoch:51 | Loss: 0.7499019751898518\n",
      "Epoch:52 | Loss: 0.7498955865783103\n",
      "Epoch:53 | Loss: 0.7498891980008467\n",
      "Epoch:54 | Loss: 0.7498828094565136\n",
      "Epoch:55 | Loss: 0.7498764209448038\n",
      "Epoch:56 | Loss: 0.7498700324652077\n",
      "Epoch:57 | Loss: 0.7498636440172208\n",
      "Epoch:58 | Loss: 0.7498572556003342\n",
      "Epoch:59 | Loss: 0.749850867214044\n",
      "Epoch:60 | Loss: 0.7498444788578396\n",
      "Epoch:61 | Loss: 0.7498380905310225\n",
      "Epoch:62 | Loss: 0.7498317022332138\n",
      "Epoch:63 | Loss: 0.7498253139639488\n",
      "Epoch:64 | Loss: 0.7498189257227367\n",
      "Epoch:65 | Loss: 0.7498125375090628\n",
      "Epoch:66 | Loss: 0.749806149323609\n",
      "Epoch:67 | Loss: 0.749799761165044\n",
      "Epoch:68 | Loss: 0.7497933730324907\n",
      "Epoch:69 | Loss: 0.7497869849254337\n",
      "Epoch:70 | Loss: 0.7497805968433653\n",
      "Epoch:71 | Loss: 0.7497742087857705\n",
      "Epoch:72 | Loss: 0.7497678207521401\n",
      "Epoch:73 | Loss: 0.7497614327413837\n",
      "Epoch:74 | Loss: 0.749755044752377\n",
      "Epoch:75 | Loss: 0.7497486567857957\n",
      "Epoch:76 | Loss: 0.749742268841125\n",
      "Epoch:77 | Loss: 0.7497358809178509\n",
      "Epoch:78 | Loss: 0.7497294930166174\n",
      "Epoch:79 | Loss: 0.7497231051365235\n",
      "Epoch:80 | Loss: 0.7497167172762789\n",
      "Epoch:81 | Loss: 0.749710329435191\n",
      "Epoch:82 | Loss: 0.7497039416128555\n",
      "Epoch:83 | Loss: 0.7496975538088259\n",
      "Epoch:84 | Loss: 0.7496911660225811\n",
      "Epoch:85 | Loss: 0.7496847782536059\n",
      "Epoch:86 | Loss: 0.749678390501387\n",
      "Epoch:87 | Loss: 0.7496720027654027\n",
      "Epoch:88 | Loss: 0.7496656150451357\n",
      "Epoch:89 | Loss: 0.7496592273413064\n",
      "Epoch:90 | Loss: 0.7496528396532033\n",
      "Epoch:91 | Loss: 0.7496464519792598\n",
      "Epoch:92 | Loss: 0.7496400643189552\n",
      "Epoch:93 | Loss: 0.7496336766717735\n",
      "Epoch:94 | Loss: 0.7496272890371762\n",
      "Epoch:95 | Loss: 0.7496209014146579\n",
      "Epoch:96 | Loss: 0.749614513803698\n",
      "Epoch:97 | Loss: 0.7496081262037715\n",
      "Epoch:98 | Loss: 0.749601738614362\n",
      "Epoch:99 | Loss: 0.7495953510349436\n",
      "Epoch:100 | Loss: 0.749588963467606\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from tn import optimizer\n",
    "\n",
    "x_1 = np.arange(-100, 100, 0.1)\n",
    "x_1 = np.expand_dims(x_1, axis=0)\n",
    "x_2 = np.arange(100, -100, 0.1)\n",
    "x_2 = np.expand_dims(x_2, axis=0)\n",
    "x = np.concatenate([x_1, x_1], axis=0).T\n",
    "y = np.sin(x.sum(axis=1))\n",
    "crit = loss.MSE()\n",
    "optim = optimizer.SGD(model.params, lr=0.1e-6)\n",
    "for i in range(100):\n",
    "    full_loss = 0\n",
    "    for j, sample in enumerate(x):\n",
    "        model.zero_grad()\n",
    "        model_format = np.array([sample])\n",
    "        out = model.forward(model_format)\n",
    "        true_res = np.array([y[j]])\n",
    "        true_res = np.expand_dims(true_res, axis=0)\n",
    "        loss_ = crit.calculate(true_res, out)\n",
    "        grad = crit.grad()\n",
    "        full_loss += loss_\n",
    "        model.backward(np.array(grad))\n",
    "        optim.update()\n",
    "    print(f'Epoch:{i + 1} | Loss: {full_loss / (x.shape[0])}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "15"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lab1.tn.graph import Node\n",
    "\n",
    "value1, value2 = Node(3), Node(12)\n",
    "value3 = value1 + value2\n",
    "\n",
    "value3.value"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from tn2 import layers as ls\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "seq = ls.Sequential([\n",
    "    ls.ConvLayer(num_filters=16, filter_width=3),\n",
    "    ls.ConvLayer(num_filters=32, filter_width=3),\n",
    "])\n",
    "\n",
    "model = ls.Network(layers=[\n",
    "    ls.ConvLayer(num_filters=3, filter_width=3),\n",
    "    seq,\n",
    "    ls.FlatLayer(),\n",
    "    ls.FCLayer_ReLU(100),\n",
    "    ls.FCLayer_Softmax(10)\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(3, 3, 32) (3, 3, 16) ()\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (3,3,32) (3,3,16) (3,3,32) ",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [3]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrandom\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrandom\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m224\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m224\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrandom\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrandom\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.1\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\MySpace\\Projects\\PTDL\\lab1\\tn2\\layers.py:245\u001B[0m, in \u001B[0;36mNetwork.train\u001B[1;34m(self, X, Y, learning_rate)\u001B[0m\n\u001B[0;32m    243\u001B[0m dA \u001B[38;5;241m=\u001B[39m A \u001B[38;5;241m-\u001B[39m Y\n\u001B[0;32m    244\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mreversed\u001B[39m(\u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers))):\n\u001B[1;32m--> 245\u001B[0m     dA \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlayers\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackpropagate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdA\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    246\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m (np\u001B[38;5;241m.\u001B[39mcopy(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers), cce, ce)\n",
      "File \u001B[1;32mC:\\MySpace\\Projects\\PTDL\\lab1\\tn2\\layers.py:263\u001B[0m, in \u001B[0;36mSequential.backpropagate\u001B[1;34m(self, dA, learning_rate)\u001B[0m\n\u001B[0;32m    261\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mbackpropagate\u001B[39m(\u001B[38;5;28mself\u001B[39m, dA, learning_rate):\n\u001B[0;32m    262\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mreversed\u001B[39m(\u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers))):\n\u001B[1;32m--> 263\u001B[0m         dA \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlayers\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackpropagate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdA\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    264\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m dA\n",
      "File \u001B[1;32mC:\\MySpace\\Projects\\PTDL\\lab1\\tn2\\layers.py:54\u001B[0m, in \u001B[0;36mConvLayer.backpropagate\u001B[1;34m(self, dZ, learning_rate)\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m f \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_f):  \u001B[38;5;66;03m# iterate over filters\u001B[39;00m\n\u001B[0;32m     53\u001B[0m     \u001B[38;5;28mprint\u001B[39m(dA_prev[i, ih1:ih2, iw1:iw2, :]\u001B[38;5;241m.\u001B[39mshape, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mW[:, :, :, f]\u001B[38;5;241m.\u001B[39mshape, dZ[i, h, w, f]\u001B[38;5;241m.\u001B[39mshape)\n\u001B[1;32m---> 54\u001B[0m     dA_prev[i, ih1:ih2, iw1:iw2, :] \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mW[:, :, :, f] \u001B[38;5;241m*\u001B[39m dZ[i, h, w, f]\n\u001B[0;32m     55\u001B[0m     dW[:, :, :, f] \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput[i, ih1:ih2, iw1:iw2, :] \u001B[38;5;241m*\u001B[39m dZ[i, h, w, f]\n\u001B[0;32m     56\u001B[0m     db[:, :, :, f] \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m dZ[i, h, w, f]\n",
      "\u001B[1;31mValueError\u001B[0m: operands could not be broadcast together with shapes (3,3,32) (3,3,16) (3,3,32) "
     ]
    }
   ],
   "source": [
    "model.train(np.random.random((1, 224, 224, 3)), Y=np.random.random((1, 10)), learning_rate=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_first_part():\n",
    "    part = ls.Sequential([\n",
    "        ls.ConvLayer(num_filters=96, filter_width=11, stride=1, padding=1),\n",
    "        ls.PoolLayer_Max(3, 2),\n",
    "        ls.ConvLayer(num_filters=256, filter_width=5, stride=1, padding=1),\n",
    "        ls.PoolLayer_Max(3, 2),\n",
    "        ls.ConvLayer(num_filters=385, filter_width=3, stride=1, padding=1),\n",
    "        ls.PoolLayer_Max(3, 1),\n",
    "\n",
    "    ])\n",
    "    return part\n",
    "\n",
    "def get_second_part():\n",
    "    part = ls.Sequential([\n",
    "        ls.ConvLayer(num_filters=384, filter_width=3, stride=1, padding=1),\n",
    "        ls.ConvLayer(num_filters=384, filter_width=3, stride=1, padding=1),\n",
    "        ls.ConvLayer(num_filters=256, filter_width=3, stride=1, padding=1),\n",
    "        ls.PoolLayer_Max(3, 2),\n",
    "        ls.FlatLayer(),\n",
    "        ls.FCLayer_ReLU(2048),\n",
    "        ls.FCLayer_ReLU(2048),\n",
    "    ])\n",
    "    return part\n",
    "\n",
    "\n",
    "l1 = get_first_part()\n",
    "l2 = get_second_part()\n",
    "r1 = get_first_part()\n",
    "r2 = get_second_part()\n",
    "last_layer = ls.FCLayer_Softmax(1000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "out1 = l1.forward_propagate(np.random.random((1, 227, 227, 3)))\n",
    "out2 = r1.forward_propagate(np.random.random((1, 227, 227, 3)))\n",
    "out_temp = out1 + out2\n",
    "out1 = out_temp\n",
    "out2 = out_temp\n",
    "out1 = l2.forward_propagate(out1)\n",
    "out2 = r2.forward_propagate(out2)\n",
    "\n",
    "out1.shape, out2.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'class_base'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Input \u001B[1;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlab1\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtn3\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mclass_base\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Module\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlab1\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtn3\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mactivations\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Tanh, Softmax\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlab1\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtn3\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlayers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Conv2D, MaxPooling, FC\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mModel\u001B[39;00m(Module):\n",
      "File \u001B[1;32mC:\\MySpace\\Projects\\PTDL\\lab1\\tn3\\activations.py:3\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mclass_base\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Layers\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mRelu\u001B[39;00m(Layers):\n\u001B[0;32m      7\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, name):\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'class_base'"
     ]
    }
   ],
   "source": [
    "from lab1.tn3.class_base import Module\n",
    "from lab1.tn3.activations import Tanh, Softmax\n",
    "from lab1.tn3.layers import Conv2D, MaxPooling, FC\n",
    "\n",
    "class Model(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = [\n",
    "            Conv2D(name=\"conv1\",in_channels= 1, out_channels= 6,kernel_size=3,stride=1,padding=1), # 1*28*28\n",
    "            MaxPooling('pool1',ksize=2,stride=2), # 6*14*14\n",
    "            Tanh(name='relu'),\n",
    "\n",
    "            Conv2D(name=\"conv2\",in_channels= 6, out_channels= 12,kernel_size=3,stride=1,padding=1),\n",
    "            MaxPooling('pool2',ksize=2,stride=2), # 12*7*7\n",
    "            Tanh(name='relu2'),\n",
    "\n",
    "            FC(name=\"full1\",in_channels= 12*7*7 , out_channels= 512),\n",
    "            Tanh(name=\"sigmoid1\"),\n",
    "            FC(name=\"full2\",in_channels=512,out_channels=128),\n",
    "            Tanh(name=\"sigmoid2\"),\n",
    "            FC(name=\"full3\",in_channels=128,out_channels=10),\n",
    "            Softmax('softmax')\n",
    "        ]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}